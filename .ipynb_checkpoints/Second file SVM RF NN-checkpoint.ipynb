{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e982ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from datetime import datetime\n",
    "import gender_guesser.detector as gender\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9750c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "    genuine_users=pd.read_csv(\"Datasets/users.csv\")\n",
    "    fake_users=pd.read_csv(\"Datasets/fusers.csv\")\n",
    "    x=pd.concat([genuine_users,fake_users])\n",
    "    y=len(fake_users)*[0]+len(genuine_users)*[1]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab920040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sex(name):\n",
    "    name=str(name)\n",
    "    sex_predictor=gender.Detector(case_sensitive=False)\n",
    "    first_name=name.split(' ')[0]\n",
    "    sex=sex_predictor.get_gender(first_name)\n",
    "    sex_dict={'female':-2,'mostly_female':-1,'unknown':0,'mostly_male':1,'male':2}\n",
    "    sex_code=sex_dict[sex]\n",
    "    return sex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5cff45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    lang_list = list(enumerate(np.unique(x['lang'])))   \n",
    "    lang_dict = { name : i for i, name in lang_list }             \n",
    "    x.loc[:,'lang_code'] = x['lang'].map( lambda x: lang_dict[x]).astype(int)    \n",
    "    x.loc[:,'sex_code']=predict_sex(x['name'])\n",
    "    feature_columns_to_use = ['statuses_count','followers_count','friends_count','favourites_count','listed_count','sex_code','lang_code']\n",
    "    x=x.loc[:,feature_columns_to_use]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812e8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1,color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7057c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,title=\"consufion matrix\",cmap=plt.cm.Blues):\n",
    "    target_names=['Fake','Genuine']\n",
    "    plt.imshow(cm,interpolation=\"nearest\",cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks=np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks,target_names,rotation=45)\n",
    "    plt.yticks(tick_marks,target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a02ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test,y_pred):\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test,y_pred)\n",
    "    print('False Positive rate:',false_positive_rate)\n",
    "    print('True Positive rate:',true_positive_rate)\n",
    "    roc_auc=auc(false_positive_rate,true_positive_rate)\n",
    "    plt.title(\"Receiver Operating Characterstics\")\n",
    "    plt.plot(false_positive_rate,true_positive_rate,'b',label='AUC = %0.2f'%roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047e32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVM(X_train, y_train, X_test, y_test):\n",
    "    \"\"\" Trains and predicts dataset with a SVM classifier \"\"\"\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': [0.1, 1, 'scale', 'auto']\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    classifier = SVC(kernel='rbf')\n",
    "    clf = GridSearchCV(classifier, param_grid=param_grid, cv=cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"The best classifier is: \",clf.best_estimator_)\n",
    "    clf.best_estimator_.fit(X_train,y_train)\n",
    "    \n",
    "    # Estimate score\n",
    "    scores = cross_val_score(clf.best_estimator_, X_train, y_train, cv=5)\n",
    "    print(scores)\n",
    "    print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.std() / 2))\n",
    "    title = 'Learning Curves (SVM, rbf kernel, $\\gamma=%.6f$)' %clf.best_estimator_.gamma\n",
    "    plot_learning_curve(clf.best_estimator_, title, X_train, y_train, cv=5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Predict class\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ffbfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def trainNN(X_train, y_train, X_test, y_test):\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Create a KerasClassifier wrapper for the Keras model\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    \n",
    "    # Set up a parameter grid for hyperparameters\n",
    "    param_grid = {'epochs': [2, 3,4], 'batch_size': [16, 32, 64]}\n",
    "    \n",
    "    # Use GridSearchCV to find the best hyperparameters\n",
    "    cvk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    clf = GridSearchCV(model, param_grid=param_grid, scoring='accuracy', cv=cvk)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"The best classifier is: \", clf.best_estimator_)\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    \n",
    "    # Estimate score\n",
    "    scores = cross_val_score(clf.best_estimator_, X_train, y_train, cv=5)\n",
    "    print(scores)\n",
    "    print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.std() / 2))\n",
    "    \n",
    "    # Predict class\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5437236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Datasetes....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>...</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>notifications</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>following</th>\n",
       "      <th>test_set_1</th>\n",
       "      <th>test_set_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.825000e+03</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>4066.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>6426.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2810.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3474.000000</td>\n",
       "      <td>3474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.499737e+08</td>\n",
       "      <td>8667.221685</td>\n",
       "      <td>717.874432</td>\n",
       "      <td>504.022564</td>\n",
       "      <td>2378.999121</td>\n",
       "      <td>9.959853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4889.145907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287853</td>\n",
       "      <td>0.141048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.662248e+08</td>\n",
       "      <td>23473.945131</td>\n",
       "      <td>12301.657025</td>\n",
       "      <td>1159.286294</td>\n",
       "      <td>8548.235726</td>\n",
       "      <td>112.952257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22037.451204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452827</td>\n",
       "      <td>0.348121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.780330e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-39600.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.597067e+08</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25200.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.168972e+08</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14400.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.174963e+09</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>1360.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.164942e+09</td>\n",
       "      <td>399555.000000</td>\n",
       "      <td>986837.000000</td>\n",
       "      <td>46310.000000</td>\n",
       "      <td>313954.000000</td>\n",
       "      <td>6166.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46800.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  statuses_count  followers_count  friends_count  \\\n",
       "count  6.825000e+03     6825.000000      6825.000000    6825.000000   \n",
       "mean   8.499737e+08     8667.221685       717.874432     504.022564   \n",
       "std    7.662248e+08    23473.945131     12301.657025    1159.286294   \n",
       "min    6.780330e+05        0.000000         0.000000       0.000000   \n",
       "25%    2.597067e+08       23.000000        12.000000     206.000000   \n",
       "50%    6.168972e+08      190.000000        33.000000     312.000000   \n",
       "75%    1.174963e+09     6900.000000       349.000000     555.000000   \n",
       "max    3.164942e+09   399555.000000    986837.000000   46310.000000   \n",
       "\n",
       "       favourites_count  listed_count  default_profile  default_profile_image  \\\n",
       "count       6825.000000   6825.000000           4066.0                   19.0   \n",
       "mean        2378.999121      9.959853              1.0                    1.0   \n",
       "std         8548.235726    112.952257              0.0                    0.0   \n",
       "min            0.000000      0.000000              1.0                    1.0   \n",
       "25%            0.000000      0.000000              1.0                    1.0   \n",
       "50%           10.000000      0.000000              1.0                    1.0   \n",
       "75%         1360.000000      2.000000              1.0                    1.0   \n",
       "max       313954.000000   6166.000000              1.0                    1.0   \n",
       "\n",
       "       geo_enabled  profile_use_background_image  ...    utc_offset  \\\n",
       "count       2294.0                        6426.0  ...   2810.000000   \n",
       "mean           1.0                           1.0  ...  -4889.145907   \n",
       "std            0.0                           0.0  ...  22037.451204   \n",
       "min            1.0                           1.0  ... -39600.000000   \n",
       "25%            1.0                           1.0  ... -25200.000000   \n",
       "50%            1.0                           1.0  ... -14400.000000   \n",
       "75%            1.0                           1.0  ...  13500.000000   \n",
       "max            1.0                           1.0  ...  46800.000000   \n",
       "\n",
       "       is_translator  follow_request_sent  protected  verified  notifications  \\\n",
       "count            1.0                  0.0       78.0      11.0            0.0   \n",
       "mean             1.0                  NaN        1.0       1.0            NaN   \n",
       "std              NaN                  NaN        0.0       0.0            NaN   \n",
       "min              1.0                  NaN        1.0       1.0            NaN   \n",
       "25%              1.0                  NaN        1.0       1.0            NaN   \n",
       "50%              1.0                  NaN        1.0       1.0            NaN   \n",
       "75%              1.0                  NaN        1.0       1.0            NaN   \n",
       "max              1.0                  NaN        1.0       1.0            NaN   \n",
       "\n",
       "       contributors_enabled  following   test_set_1   test_set_2  \n",
       "count                   0.0        0.0  3474.000000  3474.000000  \n",
       "mean                    NaN        NaN     0.287853     0.141048  \n",
       "std                     NaN        NaN     0.452827     0.348121  \n",
       "min                     NaN        NaN     0.000000     0.000000  \n",
       "25%                     NaN        NaN     0.000000     0.000000  \n",
       "50%                     NaN        NaN     0.000000     0.000000  \n",
       "75%                     NaN        NaN     1.000000     0.000000  \n",
       "max                     NaN        NaN     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading Datasetes....\\n\")\n",
    "x,y=read_datasets()\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da1d9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features....\n",
      "\n",
      "Index(['statuses_count', 'followers_count', 'friends_count',\n",
      "       'favourites_count', 'listed_count', 'sex_code', 'lang_code'],\n",
      "      dtype='object')\n",
      "       statuses_count  followers_count  friends_count  favourites_count  \\\n",
      "count     6825.000000      6825.000000    6825.000000       6825.000000   \n",
      "mean      8667.221685       717.874432     504.022564       2378.999121   \n",
      "std      23473.945131     12301.657025    1159.286294       8548.235726   \n",
      "min          0.000000         0.000000       0.000000          0.000000   \n",
      "25%         23.000000        12.000000     206.000000          0.000000   \n",
      "50%        190.000000        33.000000     312.000000         10.000000   \n",
      "75%       6900.000000       349.000000     555.000000       1360.000000   \n",
      "max     399555.000000    986837.000000   46310.000000     313954.000000   \n",
      "\n",
      "       listed_count  sex_code    lang_code  \n",
      "count   6825.000000    6825.0  6825.000000  \n",
      "mean       9.959853       0.0     5.679121  \n",
      "std      112.952257       0.0     2.527263  \n",
      "min        0.000000       0.0     0.000000  \n",
      "25%        0.000000       0.0     5.000000  \n",
      "50%        0.000000       0.0     5.000000  \n",
      "75%        2.000000       0.0     5.000000  \n",
      "max     6166.000000       0.0    25.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>sex_code</th>\n",
       "      <th>lang_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>6825.0</td>\n",
       "      <td>6825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8667.221685</td>\n",
       "      <td>717.874432</td>\n",
       "      <td>504.022564</td>\n",
       "      <td>2378.999121</td>\n",
       "      <td>9.959853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.679121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23473.945131</td>\n",
       "      <td>12301.657025</td>\n",
       "      <td>1159.286294</td>\n",
       "      <td>8548.235726</td>\n",
       "      <td>112.952257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.527263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6900.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>1360.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399555.000000</td>\n",
       "      <td>986837.000000</td>\n",
       "      <td>46310.000000</td>\n",
       "      <td>313954.000000</td>\n",
       "      <td>6166.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statuses_count  followers_count  friends_count  favourites_count  \\\n",
       "count     6825.000000      6825.000000    6825.000000       6825.000000   \n",
       "mean      8667.221685       717.874432     504.022564       2378.999121   \n",
       "std      23473.945131     12301.657025    1159.286294       8548.235726   \n",
       "min          0.000000         0.000000       0.000000          0.000000   \n",
       "25%         23.000000        12.000000     206.000000          0.000000   \n",
       "50%        190.000000        33.000000     312.000000         10.000000   \n",
       "75%       6900.000000       349.000000     555.000000       1360.000000   \n",
       "max     399555.000000    986837.000000   46310.000000     313954.000000   \n",
       "\n",
       "       listed_count  sex_code    lang_code  \n",
       "count   6825.000000    6825.0  6825.000000  \n",
       "mean       9.959853       0.0     5.679121  \n",
       "std      112.952257       0.0     2.527263  \n",
       "min        0.000000       0.0     0.000000  \n",
       "25%        0.000000       0.0     5.000000  \n",
       "50%        0.000000       0.0     5.000000  \n",
       "75%        2.000000       0.0     5.000000  \n",
       "max     6166.000000       0.0    25.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"extracting features....\\n\")\n",
    "\n",
    "x=extract_features(x)\n",
    "print(x.columns)\n",
    "print(x.describe())\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f733696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traing SVM\n",
    "y_test,y_pred = trainSVM(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "y_test,y_pred = trainNN(X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdbbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1-score: {:.2f}%\".format(f1 * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=['Fake','Genuine']))\n",
    "print(classification_report(y_test, y_pred, target_names=['Fake','Genuine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846cc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix=confusion_matrix(y_test,y_pred.round())\n",
    "print(cnf_matrix)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels=[0,1]\n",
    "sns.heatmap(cnf_matrix,annot=True,cmap=\"YlGnBu\",fmt='.3f',xticklabels=labels,yticklabels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3477857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c4844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadef29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08c066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
